{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c0c8a8-7c89-494d-8126-a00a25c714da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data manipulation packages \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63990fd-80de-47c6-a740-fbd61c3d90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import deep learning tools \n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a950350c-647f-4cea-9510-d97fd044a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 1842\n",
    "tensorflow.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# Turn off warnings for cleaner looking notebook\n",
    "warnings.simplefilter('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2338481-3287-4dc7-b07f-53c30f21e8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 430 images belonging to 2 classes.\n",
      "Found 106 images belonging to 2 classes.\n",
      "Found 100 images belonging to 1 classes.\n",
      "{'la_eterna': 0, 'other_flowers': 1}\n"
     ]
    }
   ],
   "source": [
    "#define image dataset \n",
    "#why do we rescale?\n",
    "image_generator = ImageDataGenerator(rescale=1/255, validation_split=0.2) #shear_range =.25, zoom_range =.2, horizontal_flip = True, rotation_range=20)     \n",
    "\n",
    "#Train & Validation Split \n",
    "train_dataset = image_generator.flow_from_directory(batch_size=10,\n",
    "                                                 directory='data_cleaned/Train',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(224, 224), \n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "validation_dataset = image_generator.flow_from_directory(batch_size=10,\n",
    "                                                 directory='data_cleaned/Train',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(224, 224), \n",
    "                                                 subset=\"validation\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "#Organize data for our predictions \n",
    "image_generator_submission = ImageDataGenerator(rescale=1/255) \n",
    "submission = image_generator_submission.flow_from_directory(\n",
    "                                                 directory='data_cleaned/scraped_images',\n",
    "                                                 shuffle=False,\n",
    "                                                 target_size=(224, 224), \n",
    "                                                 class_mode=None)\n",
    "\n",
    "\n",
    "class_indices = train_dataset.class_indices\n",
    "print(class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b7e1d50-a6b0-4a48-998b-a372dbf7a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the first batch of data\n",
    "batch_images, batch_labels = train_dataset.next()\n",
    "\n",
    "# Define a function to convert one-hot encoded labels to class names\n",
    "def decode_label(one_hot_label):\n",
    "    return list(train_dataset.class_indices.keys())[np.argmax(one_hot_label)]\n",
    "\n",
    "# Iterate over the batch\n",
    "for i in range(len(batch_images)):\n",
    "    image = batch_images[i]\n",
    "    label = batch_labels[i]\n",
    "    \n",
    "    # Decode the label\n",
    "    decoded_label = decode_label(label)\n",
    "    \n",
    "    # Display the image and label\n",
    "    plt.imshow(image)\n",
    "    plt.title(decoded_label)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91891e0c-c50c-41e5-a34b-c09e5893670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Define the layers\n",
    "conv1 = Conv2D(15, 3, activation='relu', input_shape=[224, 224, 3])\n",
    "maxpool1 = MaxPooling2D()\n",
    "conv2 = Conv2D(15, 3, activation='relu')\n",
    "maxpool2 = MaxPooling2D()\n",
    "dropout = Dropout(0.5)\n",
    "flatten = Flatten()\n",
    "dense1 = Dense(64, activation='relu')\n",
    "dense2 = Dense(2, activation='softmax')\n",
    "\n",
    "# Construct the model\n",
    "model = keras.models.Sequential([\n",
    "    conv1,\n",
    "    maxpool1,\n",
    "    conv2,\n",
    "    maxpool2,\n",
    "    dropout,\n",
    "    flatten,\n",
    "    dense1,\n",
    "    dense2\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68fa6234-6649-4c55-a27f-2dd83c59722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=3,\n",
    "                                         restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6f7b3f6-8a69-4e27-9533-aed809bb4646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 4s 99ms/step - loss: 0.2132 - accuracy: 0.9140 - val_loss: 0.5308 - val_accuracy: 0.8019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18c13f7eac0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=5, validation_data=validation_dataset, callbacks=callback)\n",
    "#save model\n",
    "#early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b9cee40-fe9e-439b-bb4a-41011ee3ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 46ms/step - loss: 0.5308 - accuracy: 0.8019\n",
      "Loss: 0.5307663679122925\n",
      "Accuracy: 0.801886796951294\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validation_dataset)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dc84252-3d2d-4b91-bb29-9f44a258a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 110ms/step\n"
     ]
    }
   ],
   "source": [
    "model.predict(submission);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ff32cf-94ac-4856-8279-73d87c3956c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 15)      420       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 15)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 15)      2040      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 15)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 54, 54, 15)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 43740)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2799424   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,802,014\n",
      "Trainable params: 2,802,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbbe6638-be04-43d5-9d1c-d30d8f9a915c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18c13fbda90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ec31c45-92c4-4dd5-8162-59a071c0e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>la_eterna</th>\n",
       "      <th>other_flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.994076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_01</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>0.926307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_03</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.995999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_04</td>\n",
       "      <td>0.036987</td>\n",
       "      <td>0.963013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>img_95</td>\n",
       "      <td>0.381451</td>\n",
       "      <td>0.618549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>img_96</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.990387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>img_97</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>img_98</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.999583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>img_99</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.998898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    images  la_eterna  other_flower\n",
       "0   img_00   0.005924      0.994076\n",
       "1   img_01   0.000040      0.999960\n",
       "2   img_02   0.073693      0.926307\n",
       "3   img_03   0.004001      0.995999\n",
       "4   img_04   0.036987      0.963013\n",
       "..     ...        ...           ...\n",
       "95  img_95   0.381451      0.618549\n",
       "96  img_96   0.009613      0.990387\n",
       "97  img_97   0.352000      0.648000\n",
       "98  img_98   0.000417      0.999583\n",
       "99  img_99   0.001102      0.998898\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles = [f.split('.')[0] for f in os.listdir(os.path.join('data_cleaned/scraped_images/image_files')) if os.path.isfile(os.path.join(os.path.join('data_cleaned/scraped_images/image_files'), f))]\n",
    "submission_df = pd.DataFrame(onlyfiles, columns =['images'])\n",
    "submission_df[['la_eterna','other_flower']] = model.predict(submission)\n",
    "submission_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dd3e14f-a979-425c-bfa0-ba7d35260b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>la_eterna</th>\n",
       "      <th>other_flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.994076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_01</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02</td>\n",
       "      <td>0.073693</td>\n",
       "      <td>0.926307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_03</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.995999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_04</td>\n",
       "      <td>0.036987</td>\n",
       "      <td>0.963013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   images  la_eterna  other_flower\n",
       "0  img_00   0.005924      0.994076\n",
       "1  img_01   0.000040      0.999960\n",
       "2  img_02   0.073693      0.926307\n",
       "3  img_03   0.004001      0.995999\n",
       "4  img_04   0.036987      0.963013"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you've defined your model and loaded the images\n",
    "# model = ...  # Your model definition\n",
    "# submission = ...  # Your collection of images\n",
    "\n",
    "image_files_dir = 'data_cleaned/scraped_images/image_files'\n",
    "onlyfiles = [f.split('.')[0] for f in os.listdir(image_files_dir) if os.path.isfile(os.path.join(image_files_dir, f))]\n",
    "\n",
    "submission_df = pd.DataFrame(onlyfiles, columns=['images'])\n",
    "\n",
    "# Assuming your model predicts two classes and returns probabilities for each\n",
    "# Change the prediction logic based on your model's output structure\n",
    "predictions = model.predict(submission)\n",
    "submission_df[['la_eterna', 'other_flower']] = predictions\n",
    "\n",
    "submission_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4a8bb84-e9db-4fae-9cdb-b6763dcf1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Construct the model\n",
    "model_a = keras.models.Sequential([\n",
    "    conv1,\n",
    "    maxpool1,\n",
    "    conv2,\n",
    "    maxpool2,\n",
    "    dropout,\n",
    "    flatten,\n",
    "    dense1,\n",
    "    dense2\n",
    "])\n",
    "\n",
    "# Create an ImageDataGenerator instance with desired augmentation parameters\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.9, 1.1]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89b415fb-028d-4c07-84ac-c9ed2ab6ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.compile(loss = 'binary_crossentropy',optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=3,\n",
    "                                         restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "678ad499-ade6-4753-93e6-4a3eaf132586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 106ms/step - loss: 0.2162 - accuracy: 0.9070 - val_loss: 0.3128 - val_accuracy: 0.8396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18c1409c5e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.fit(train_dataset, epochs=5, validation_data=validation_dataset, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c8d20bb-e210-41bc-8050-b031b57f7215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 36ms/step - loss: 0.3128 - accuracy: 0.8396\n",
      "Loss: 0.3127584159374237\n",
      "Accuracy: 0.8396226167678833\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_a.evaluate(validation_dataset)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d8ed233-88d3-47e9-8c35-dc9324e740d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 73ms/step\n"
     ]
    }
   ],
   "source": [
    "x=model_a.predict(submission);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc6ce6f3-d6e3-48b6-b081-12c09967ab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = np.argmax(x, axis=1)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "312b1dd2-f00e-434c-828d-81cb613649ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pd.DataFrame(predicted_classes, columns=['predicted_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "196548e7-3ad9-40f5-b794-343b83df3ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 87ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>la_eterna</th>\n",
       "      <th>other_flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_01</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.999627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_03</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_04</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.996538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   images  la_eterna  other_flower\n",
       "0  img_00   0.000018      0.999982\n",
       "1  img_01   0.000008      0.999992\n",
       "2  img_02   0.000373      0.999627\n",
       "3  img_03   0.000010      0.999990\n",
       "4  img_04   0.003462      0.996538"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles = [f.split('.')[0] for f in os.listdir(os.path.join('data_cleaned/scraped_images/image_files')) if os.path.isfile(os.path.join(os.path.join('data_cleaned/scraped_images/image_files'), f))]\n",
    "submission_df = pd.DataFrame(onlyfiles, columns =['images'])\n",
    "submission_df[['la_eterna','other_flower']] = model.predict(submission)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82371088-d53b-4391-9e61-a0f11cba7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_file.csv', index = False)\n",
    "\n",
    "# Assuming your model is named 'model'\n",
    "model.save('model_a.h5')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
