{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c0c8a8-7c89-494d-8126-a00a25c714da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data manipulation packages \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63990fd-80de-47c6-a740-fbd61c3d90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import deep learning tools \n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout, Concatenate, experimental\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a950350c-647f-4cea-9510-d97fd044a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 1842\n",
    "tensorflow.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# Turn off warnings for cleaner looking notebook\n",
    "warnings.simplefilter('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2338481-3287-4dc7-b07f-53c30f21e8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 430 images belonging to 2 classes.\n",
      "Found 106 images belonging to 2 classes.\n",
      "Found 100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#define image dataset \n",
    "#why do we rescale?\n",
    "image_generator = ImageDataGenerator(rescale=1/255, validation_split=0.2) #shear_range =.25, zoom_range =.2, horizontal_flip = True, rotation_range=20)     \n",
    "\n",
    "#Train & Validation Split \n",
    "train_dataset = image_generator.flow_from_directory(batch_size=10,\n",
    "                                                 directory='data_cleaned/Train',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(224, 224), \n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "validation_dataset = image_generator.flow_from_directory(batch_size=10,\n",
    "                                                 directory='data_cleaned/Train',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(224, 224), \n",
    "                                                 subset=\"validation\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "#Organize data for our predictions \n",
    "image_generator_submission = ImageDataGenerator(rescale=1/255) \n",
    "submission = image_generator_submission.flow_from_directory(\n",
    "                                                 directory='data_cleaned/scraped_images',\n",
    "                                                 shuffle=False,\n",
    "                                                 target_size=(224, 224), \n",
    "                                                 class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7194d6-aa4e-42bc-9671-a170b991c406",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the first batch of data\n",
    "batch_images, batch_labels = train_dataset.next()\n",
    "\n",
    "# Define a function to convert one-hot encoded labels to class names\n",
    "def decode_label(one_hot_label):\n",
    "    return list(train_dataset.class_indices.keys())[np.argmax(one_hot_label)]\n",
    "\n",
    "# Iterate over the batch\n",
    "for i in range(len(batch_images)):\n",
    "    image = batch_images[i]\n",
    "    label = batch_labels[i]\n",
    "    \n",
    "    # Decode the label\n",
    "    decoded_label = decode_label(label)\n",
    "    \n",
    "    # Display the image and label\n",
    "    plt.imshow(image)\n",
    "    plt.title(decoded_label)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91891e0c-c50c-41e5-a34b-c09e5893670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Define the layers\n",
    "conv1 = Conv2D(15, 3, activation='relu', input_shape=[224, 224, 3])\n",
    "maxpool1 = MaxPooling2D()\n",
    "conv2 = Conv2D(15, 3, activation='relu')\n",
    "maxpool2 = MaxPooling2D()\n",
    "dropout = Dropout(0.5)\n",
    "flatten = Flatten()\n",
    "dense1 = Dense(64, activation='relu')\n",
    "dense2 = Dense(2, activation='softmax')\n",
    "\n",
    "# Construct the model\n",
    "model = keras.models.Sequential([\n",
    "    conv1,\n",
    "    maxpool1,\n",
    "    conv2,\n",
    "    maxpool2,\n",
    "    dropout,\n",
    "    flatten,\n",
    "    dense1,\n",
    "    dense2\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68fa6234-6649-4c55-a27f-2dd83c59722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=3,\n",
    "                                         restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6f7b3f6-8a69-4e27-9533-aed809bb4646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 5s 91ms/step - loss: 0.7962 - accuracy: 0.6930 - val_loss: 0.5891 - val_accuracy: 0.7075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e774419460>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=1, validation_data=validation_dataset, callbacks=callback)\n",
    "#save model\n",
    "#early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b9cee40-fe9e-439b-bb4a-41011ee3ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 37ms/step - loss: 0.5891 - accuracy: 0.7075\n",
      "Loss: 0.5891367793083191\n",
      "Accuracy: 0.7075471878051758\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validation_dataset)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dc84252-3d2d-4b91-bb29-9f44a258a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 70ms/step\n"
     ]
    }
   ],
   "source": [
    "model.predict(submission);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8ff32cf-94ac-4856-8279-73d87c3956c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 222, 222, 15)      420       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 111, 111, 15)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 109, 109, 15)      2040      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 54, 54, 15)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 54, 54, 15)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 43740)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2799424   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,802,014\n",
      "Trainable params: 2,802,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbbe6638-be04-43d5-9d1c-d30d8f9a915c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e77334fb50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ec31c45-92c4-4dd5-8162-59a071c0e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>la_eterna</th>\n",
       "      <th>other_flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00</td>\n",
       "      <td>0.234894</td>\n",
       "      <td>0.765106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_01</td>\n",
       "      <td>0.193672</td>\n",
       "      <td>0.806328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02</td>\n",
       "      <td>0.254050</td>\n",
       "      <td>0.745950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_03</td>\n",
       "      <td>0.232871</td>\n",
       "      <td>0.767129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_04</td>\n",
       "      <td>0.206572</td>\n",
       "      <td>0.793428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>img_95</td>\n",
       "      <td>0.277663</td>\n",
       "      <td>0.722337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>img_96</td>\n",
       "      <td>0.288130</td>\n",
       "      <td>0.711870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>img_97</td>\n",
       "      <td>0.234220</td>\n",
       "      <td>0.765780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>img_98</td>\n",
       "      <td>0.191308</td>\n",
       "      <td>0.808692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>img_99</td>\n",
       "      <td>0.186527</td>\n",
       "      <td>0.813473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    images  la_eterna  other_flower\n",
       "0   img_00   0.234894      0.765106\n",
       "1   img_01   0.193672      0.806328\n",
       "2   img_02   0.254050      0.745950\n",
       "3   img_03   0.232871      0.767129\n",
       "4   img_04   0.206572      0.793428\n",
       "..     ...        ...           ...\n",
       "95  img_95   0.277663      0.722337\n",
       "96  img_96   0.288130      0.711870\n",
       "97  img_97   0.234220      0.765780\n",
       "98  img_98   0.191308      0.808692\n",
       "99  img_99   0.186527      0.813473\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles = [f.split('.')[0] for f in os.listdir(os.path.join('data_cleaned/scraped_images/image_files')) if os.path.isfile(os.path.join(os.path.join('data_cleaned/scraped_images/image_files'), f))]\n",
    "submission_df = pd.DataFrame(onlyfiles, columns =['images'])\n",
    "submission_df[['la_eterna','other_flower']] = model.predict(submission)\n",
    "submission_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dd3e14f-a979-425c-bfa0-ba7d35260b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>la_eterna</th>\n",
       "      <th>other_flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00</td>\n",
       "      <td>0.234894</td>\n",
       "      <td>0.765106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_01</td>\n",
       "      <td>0.193672</td>\n",
       "      <td>0.806328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02</td>\n",
       "      <td>0.254050</td>\n",
       "      <td>0.745950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_03</td>\n",
       "      <td>0.232871</td>\n",
       "      <td>0.767129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_04</td>\n",
       "      <td>0.206572</td>\n",
       "      <td>0.793428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   images  la_eterna  other_flower\n",
       "0  img_00   0.234894      0.765106\n",
       "1  img_01   0.193672      0.806328\n",
       "2  img_02   0.254050      0.745950\n",
       "3  img_03   0.232871      0.767129\n",
       "4  img_04   0.206572      0.793428"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you've defined your model and loaded the images\n",
    "# model = ...  # Your model definition\n",
    "# submission = ...  # Your collection of images\n",
    "\n",
    "image_files_dir = 'data_cleaned/scraped_images/image_files'\n",
    "onlyfiles = [f.split('.')[0] for f in os.listdir(image_files_dir) if os.path.isfile(os.path.join(image_files_dir, f))]\n",
    "\n",
    "submission_df = pd.DataFrame(onlyfiles, columns=['images'])\n",
    "\n",
    "# Assuming your model predicts two classes and returns probabilities for each\n",
    "# Change the prediction logic based on your model's output structure\n",
    "predictions = model.predict(submission)\n",
    "submission_df[['la_eterna', 'other_flower']] = predictions\n",
    "\n",
    "submission_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4a8bb84-e9db-4fae-9cdb-b6763dcf1358",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.layers' has no attribute 'experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_augmentation \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mRandomFlip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mRandomRotation(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m      4\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mRandomZoom(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m      5\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mRandomContrast(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m      6\u001b[0m ])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.layers' has no attribute 'experimental'"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(224,224,3)),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "    keras.layers.RandomContrast(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3e4263a-1bb7-4d3a-a117-e0fa5d381d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = Sequential([data_augmentation, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89b415fb-028d-4c07-84ac-c9ed2ab6ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.compile(loss = 'binary_crossentropy',optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                         patience=3,\n",
    "                                         restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "678ad499-ade6-4753-93e6-4a3eaf132586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "43/43 [==============================] - 12s 128ms/step - loss: 0.5411 - accuracy: 0.7372 - val_loss: 0.4389 - val_accuracy: 0.8396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e77348dfd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.fit(train_dataset, epochs=1, validation_data=validation_dataset, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c8d20bb-e210-41bc-8050-b031b57f7215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4389 - accuracy: 0.8396\n",
      "Loss: 0.4388771653175354\n",
      "Accuracy: 0.8396226167678833\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_a.evaluate(validation_dataset)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d8ed233-88d3-47e9-8c35-dc9324e740d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 83ms/step\n"
     ]
    }
   ],
   "source": [
    "x=model_a.predict(submission);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc6ce6f3-d6e3-48b6-b081-12c09967ab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = np.argmax(x, axis=1)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "312b1dd2-f00e-434c-828d-81cb613649ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pd.DataFrame(predicted_classes, columns=['predicted_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "196548e7-3ad9-40f5-b794-343b83df3ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 79ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>la_eterna</th>\n",
       "      <th>other_flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00</td>\n",
       "      <td>0.066763</td>\n",
       "      <td>0.933237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_01</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.993820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02</td>\n",
       "      <td>0.144766</td>\n",
       "      <td>0.855234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_03</td>\n",
       "      <td>0.117694</td>\n",
       "      <td>0.882306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_04</td>\n",
       "      <td>0.059073</td>\n",
       "      <td>0.940927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   images  la_eterna  other_flower\n",
       "0  img_00   0.066763      0.933237\n",
       "1  img_01   0.006180      0.993820\n",
       "2  img_02   0.144766      0.855234\n",
       "3  img_03   0.117694      0.882306\n",
       "4  img_04   0.059073      0.940927"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles = [f.split('.')[0] for f in os.listdir(os.path.join('data_cleaned/scraped_images/image_files')) if os.path.isfile(os.path.join(os.path.join('data_cleaned/scraped_images/image_files'), f))]\n",
    "submission_df = pd.DataFrame(onlyfiles, columns =['images'])\n",
    "submission_df[['la_eterna','other_flower']] = model.predict(submission)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82371088-d53b-4391-9e61-a0f11cba7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_file.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de90472-ebdd-464b-a4d8-fa63b10ccbdb",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bed25573-e320-47dc-bdda-94a505a0a2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\suleman\\anaconda3\\envs\\test2\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\suleman\\anaconda3\\envs\\test2\\lib\\site-packages (from keras-tuner) (2.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\suleman\\anaconda3\\envs\\test2\\lib\\site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\suleman\\anaconda3\\envs\\test2\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\suleman\\anaconda3\\envs\\test2\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\suleman\\anaconda3\\envs\\test2\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\suleman\\anaconda3\\envs\\test2\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\suleman\\anaconda3\\envs\\test2\\lib\\site-packages (from requests->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suleman\\anaconda3\\envs\\test2\\lib\\site-packages (from requests->keras-tuner) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6ef07-3661-4b23-98d3-7c7039ab800a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5fdf06-cfd4-497a-99b9-0b7200d5f2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
